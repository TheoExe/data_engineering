{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bd85f0-24c3-45d3-975d-4838c1036ab9",
   "metadata": {},
   "source": [
    "# DBT Lab\n",
    "In this lab, we're going to combine the last tool we explored, Snowflake, and use it via DBT so we can see how together they make a more complete data analysis system.  There are two ways to run DBT, one similar to Snowflake where we can go via a Web UI, but to really leverage the open source and the capabilities of team collaboration, we'll use the command line version.  We'll set up from scratch and tie into our Snowflake account.\n",
    "\n",
    " - 1 Install dbt at the command line\n",
    " - 2 Set up config file to connect and test connection to Snowflake\n",
    " - 3 Query our data using SQL\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6970c-07e8-4d44-9d62-19a5a7025dc6",
   "metadata": {},
   "source": [
    "## 1 Installing DBT at the command line\n",
    "In this step, we'll create a quick virtual environment and install dbt, then setup our first project.  We'll use `first-project` as the name of our first project in the following steps:\n",
    "\n",
    "### Requirements\n",
    "* Python 3.6 or higher\n",
    "\n",
    "\n",
    "* Create a virtual environment with `python3 -m venv env`\n",
    "* Activate the environment with `source env/bin/activate`\n",
    "* Install with `pip install dbt`\n",
    "* Initialize a project with `dbt init first-project`\n",
    "\n",
    "* NOTE: If you see with markupsafe, use `pip uninstall markupsafe` and re-install `pip install markupsafe==2.0.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca218d9f-04ef-476a-b6e9-70a85901520b",
   "metadata": {},
   "source": [
    "## 2 Set up connection to and test Snowflake\n",
    "Let's now set up the yaml config file needed to connect DBT with Snowflake.\n",
    "\n",
    "For reference: [Supported Data Platforms](https://docs.getdbt.com/docs/supported-data-platforms)\n",
    "\n",
    "### Requirements\n",
    "For this section, you will need three things from the snowflake account we set up in the previous lecture\n",
    "* Username (EOlivaresEVI)\n",
    "* Password (********)\n",
    "* The first portion of the url which is your account id.  (rja95216)\n",
    "\n",
    "### 2.1 Preparing Snowflake\n",
    "Let's create a warehouse for use with our DBT connection, as well as a user specifically for this use.\n",
    "* Log into your snowflake account.\n",
    "* Using the role `ACCOUNTADMIN`, go to `Admin->Warehouses`\n",
    "* Lets use...\n",
    "    - name: dbt_warehouse\n",
    "    - size: X-Xmall 1 credit/hour\n",
    "    - Advanced Warehouse Options/Suspend After (min): 5\n",
    "    \n",
    "#### Add a specific dbt user and role\n",
    "* Now let's go to `Admin/Users & Roles`\n",
    "* Use the `[+User]` button to create a new user\n",
    "* Select a name, and a password, and write them down, as we'll use them in the configuration step next.\n",
    "* Uncheck the box for `Force user to change password on first time login`\n",
    "* dbt_transform/DbtTra@nsform1\n",
    "* Now let's got o `Roles` and `[+Role]`\n",
    "* Note the name of the new role, then from the `Roles/Table` use the `[...]` button on the right to select `Grant/Grant to User`\n",
    "* Select your user and then repeat the process to grant to the user specific to dbt. (We want both, one to use with our connection, and one to use if we need to debug)\n",
    "\n",
    "#### Add a database and schema\n",
    "* Go to `Data/Databases` and create `ANALYTICS` database\n",
    "* After creating it, open the link to it on the UI and go to the `[+privileges]` button on the right\n",
    "* Select the role `ACCOUNTADMIN` and grant privileges for `CREATE SCHEMA`, `MODIFY`, `USAGE`.\n",
    "* Repeat the process for the `DBT_TRANSFORM_ROLE`\n",
    "* Now let's go to a worksheet so we can create a schema in the database.\n",
    "* In the worksheet, let's execute `CREATE SCHEMA analytics.dbt;`\n",
    "* Click on the dabase view on the left menu, and refresh.  We should be able to see our new schema now.\n",
    "\n",
    "### 2.2 Setting up the connection\n",
    "When we ran `dbt init` it set up a config for us.  We can run `dbt debug --config-dir` to find it's default location. We'll need to edit this file to set up our Snowflake location.  Open the file, by default at `~/.dbt/profiles.yml` and it should look like this:\n",
    "```yaml\n",
    "jaffle_shop: # this needs to match the profile: in your dbt_project.yml file\n",
    "  target: dev\n",
    "  outputs:\n",
    "    dev:\n",
    "      type: bigquery\n",
    "      method: service-account\n",
    "      keyfile: /Users/eolivares/.dbt/dbt-practice-210412-b994f6a6e03a.json # replace this with the full path to your keyfile\n",
    "      project: dbt-practice-210412 # Replace this with your project id\n",
    "      dataset: dbt_efrain # Replace this with dbt_your_name, e.g. dbt_bob\n",
    "      threads: 1\n",
    "      timeout_seconds: 300\n",
    "      location: US\n",
    "      priority: interactive\n",
    "```\n",
    "\n",
    "We'll replace it wiht the following\n",
    "```yaml\n",
    "dbt-snowflake-connection: # this needs to match the profile: in your dbt_project.yml file\n",
    "  target: dev\n",
    "  outputs:\n",
    "    dev:\n",
    "      type: snowflake\n",
    "      account: rja95216\n",
    "\n",
    "      user: dbt_transform\n",
    "      password: <the password set for dbt_transform>\n",
    "\n",
    "      role: dbt_transform_role\n",
    "\n",
    "\n",
    "      dataset: analytics\n",
    "      warehouse: dbt_warehouse\n",
    "      schema: dbt\n",
    "      threads: 1                         # number of models to run at a time, we'll start with 1\n",
    "      client_session_keep_alive: False   # do not keep snowflake session open after a run (save credits)\n",
    "```\n",
    "\n",
    "#### 2.3 Final configuration in dbt_project.yml\n",
    "Now that we set up the connection yaml, we'll need to put everything together in our working dbt space at the cli.\n",
    "Back at the directory where you executed `dbt init`\n",
    "* Open `dbt_project.yml`\n",
    "* Pick a name for the project for `name:`.  This will be used in the name of the path to store sql as we'll see next.  Say for example, `dbt_first_project`\n",
    "* The `profile:` should be set to the same name as you used in `.dbt/profiles.yml`\n",
    "* Near the bottom, under `models:`, use the name of the project so it looks like this\n",
    "```yaml\n",
    "...\n",
    "models:\n",
    "  dbt_first_project:\n",
    "    # Config indicated by + and applies to all files under models/example/\n",
    "    example:\n",
    "      +materialized: view\n",
    "```\n",
    "\n",
    "Debugging tips:\n",
    "* Some urls, where you get your account from for snowflake, include a region, so if you see something like `us-west-1` just before the `snowflake...` text in the url, it is part of your account name.\n",
    "* The username is not case sensitive, thus `dbt_transformer` is the same as `DBT_TRANSFORMER`, however, as expected, the password is case sensitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9de901-75d2-47e7-9ab5-e6f388d4863e",
   "metadata": {},
   "source": [
    "# 3 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
